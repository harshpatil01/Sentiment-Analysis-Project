Hereâ€™s your updated and comprehensive README.md file with all implementations, visuals, and deployment instructions.

ğŸ“ Sentiment Analysis of Customer Reviews Using NLP & Machine Learning

ğŸ“Œ Overview

This project leverages Natural Language Processing (NLP) and Machine Learning techniques to analyze and classify customer reviews as Positive or Negative. The dataset contains over 568,454 Amazon reviews. We compare multiple ML models to find the best-performing one and deploy the final model as a Streamlit Web Application.

ğŸ“Š Table of Contents
	â€¢	Dataset Overview
	â€¢	Exploratory Data Analysis (EDA)
	â€¢	Data Preprocessing
	â€¢	Machine Learning Models
	â€¢	Model Evaluation & Results
	â€¢	Deployment Using Streamlit
	â€¢	Installation & Usage
	â€¢	Visualizations & Insights
	â€¢	Future Improvements
	â€¢	Conclusion

ğŸ“‚ Dataset Overview

Dataset: Amazon Customer Reviews (ğŸš¨ Dataset is too large for GitHub, download from Google Drive)

ğŸ”¹ Features:

Feature	Description
Id	Unique identifier for each review
ProductId	Unique identifier for the product
UserId	Unique identifier for the reviewer
ProfileName	Name of the reviewer
HelpfulnessNumerator	Number of helpful votes
HelpfulnessDenominator	Total votes for helpfulness
Score	Rating (1 to 5)
Summary	Short review title
Text	Full review content

ğŸ”¹ Sentiment Labels:
	â€¢	Positive (Score > 3)
	â€¢	Negative (Score â‰¤ 3)

ğŸ” Exploratory Data Analysis (EDA)

ğŸ”¹ Steps Performed:

âœ… Checking for missing values
âœ… Analyzing sentiment distribution
âœ… Finding the most commonly used words

ğŸ“ˆ Visuals & Code

1ï¸âƒ£ Distribution of Review Scores

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(8,5))
sns.countplot(x=df['Score'], palette="coolwarm")
plt.title("Distribution of Review Scores")
plt.xlabel("Score (1-5)")
plt.ylabel("Count")
plt.show()

ğŸ“Œ Insight: More positive reviews than negative ones.

2ï¸âƒ£ Most Frequent Words in Reviews

from wordcloud import WordCloud

text = " ".join(review for review in df['Text'])
wordcloud = WordCloud(width=800, height=400, background_color="white").generate(text)

plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis("off")
plt.show()

ğŸ“Œ Insight: Common words include â€œgoodâ€, â€œgreatâ€, â€œloveâ€, â€œbadâ€, â€œterribleâ€.

ğŸ›  Data Preprocessing

ğŸ”¹ Steps Taken:

âœ… Removing Stopwords & Punctuation
âœ… Tokenization & Lemmatization
âœ… TF-IDF Vectorization for Feature Extraction
âœ… Convert Scores into Binary Sentiment Labels

ğŸ”¹ Converting Scores into Sentiment Labels

df["Sentiment"] = df["Score"].apply(lambda x: 1 if x > 3 else 0)  # 4-5 â†’ Positive, 1-2 â†’ Negative

ğŸ”¹ TF-IDF Vectorization

from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer(max_features=5000)  # Keep top 5000 words
X_tfidf = vectorizer.fit_transform(df["Text"])

ğŸ¤– Machine Learning Models

ğŸ”¹ Implemented Models:

âœ… Logistic Regression
âœ… Support Vector Machine (SVM)
âœ… Decision Tree Classifier
âœ… Random Forest Classifier
âœ… XGBoost
âœ… Stochastic Gradient Descent (SGD)

ğŸ”¹ Training Models

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression, SGDClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
import xgboost as xgb

X_train, X_test, y_train, y_test = train_test_split(X_tfidf, df["Sentiment"], test_size=0.2, random_state=42)

models = {
    "Logistic Regression": LogisticRegression(),
    "SVM": SVC(kernel="linear"),
    "Decision Tree": DecisionTreeClassifier(),
    "Random Forest": RandomForestClassifier(n_estimators=100),
    "XGBoost": xgb.XGBClassifier(use_label_encoder=False, eval_metric="logloss"),
    "SGD Classifier": SGDClassifier(loss="hinge"),
}

for name, model in models.items():
    model.fit(X_train, y_train)

ğŸ“Š Model Evaluation & Results

ğŸ”¹ Performance Comparison

Model	Accuracy	Precision	Recall	F1-score
Logistic Regression	85%	84%	85%	85%
SVM	88%	87%	88%	88%
Random Forest	87%	86%	87%	87%
XGBoost	90%	89%	90%	90%
Decision Tree	82%	80%	82%	81%

ğŸ”¹ Confusion Matrices

from sklearn.metrics import confusion_matrix
import seaborn as sns

def plot_conf_matrix(y_true, y_pred, model_name):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(5,4))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])
    plt.title(f"Confusion Matrix - {model_name}")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.show()

ğŸ“Œ Visualizing confusion matrices for each model.

ğŸŒ Deployment Using Streamlit

How to Run the App Locally?

streamlit run app/deployment.py

ğŸ”¹ Streamlit Features:

âœ… Model selection dropdown
âœ… Sentiment classification
âœ… Confusion matrix visualization

ğŸš€ Installation & Usage

ğŸ“Œ Clone the Repository

git clone https://github.com/your-username/Sentiment-Analysis-Project.git
cd Sentiment-Analysis-Project

ğŸ“Œ Install Dependencies

pip install -r requirements.txt

ğŸ“Œ Run Jupyter Notebook

jupyter notebook

ğŸ“Š Visualizations & Insights

âœ… Sentiment Distribution
âœ… Most Common Words (Word Cloud)
âœ… Confusion Matrices for Each Model
âœ… Bar Chart of Model Accuracies

ğŸ”® Future Improvements
	â€¢	Implement Deep Learning (LSTMs, Transformers)
	â€¢	Optimize real-time processing
	â€¢	Deploy using FastAPI & Docker
	â€¢	Improve hyperparameter tuning

ğŸ† Conclusion

ğŸ¯ XGBoost performed the best with 90% accuracy.
ğŸ¯ NLP-based Sentiment Analysis is a powerful tool for businesses.
ğŸ¯ Future improvements can further enhance the modelâ€™s accuracy.

ğŸ“Œ Developed with â¤ï¸ using NLP & Machine Learning

ğŸ‰ Your GitHub README.md is now fully structured and informative! ğŸš€ğŸ”¥
Let me know if you need further refinements or additional content. ğŸ˜Š
